{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Height vs Weight\r\n",
    "\r\n",
    "Welcome to Core Workshop 4: Polynomial Regression's live code session\r\n",
    "\r\n",
    "Today we are dealing with a csv toy dataset taken from Kaggle: [https://www.kaggle.com/sakshamjn/heightvsweight-for-linear-polynomial-regression](https://www.kaggle.com/sakshamjn/heightvsweight-for-linear-polynomial-regression), which records the **weight** and **height** of people (they are made up). The data is already cleaned.\r\n",
    "\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## In this session we are using this data to build a `polynomial regression` model, trying to predict the **height** by a given **weight**, using k-folds cross validation method to find optimal hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explore"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Repeat previous processing\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df = pd.read_csv(\"./data/HeightVsWeight.csv\")\r\n",
    "\r\n",
    "x = df.iloc[:, :1]\r\n",
    "y = df.iloc[:, 1:]\r\n",
    "\r\n",
    "plt.figure(figsize=(15, 6))\r\n",
    "plt.scatter(x, y, color=\"purple\")\r\n",
    "plt.xlabel(\"Weight\")\r\n",
    "plt.ylabel(\"Height\")\r\n",
    "plt.title(\"Height VS Weight\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split using k-folds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We are going to split the training data into 5 folds, which is common number used for small datasets\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold, train_test_split\r\n",
    "\r\n",
    "# Regular train test split\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=1)\r\n",
    "\r\n",
    "# Build 5-folds split, split by index\r\n",
    "kf5 = KFold(n_splits=5)\r\n",
    "\r\n",
    "# Save the train index and validate index\r\n",
    "t_v_indexes = []\r\n",
    "\r\n",
    "for train_index, validation_index in kf5.split(x_train):\r\n",
    "    t_v_indexes.append([train_index, validation_index])\r\n",
    "    print(\"Train: {} | Validate: {}\".format(train_index, validation_index))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training (Hyperparameter optimization)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We are iterating through each fold, for a range of hyperparameter, and take average accuracy to find the best hyperparameter\r\n",
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "\r\n",
    "\r\n",
    "# Let's range it to 10, because it doesn't seem to be a very tortuous dataset\r\n",
    "n = 20\r\n",
    "\r\n",
    "hyper_average = dict()\r\n",
    "\r\n",
    "# For each degree setting\r\n",
    "for i in range (1, n+1):\r\n",
    "\r\n",
    "    # Build respective pipeline and initialize sum\r\n",
    "    sum = 0\r\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree=i), LinearRegression())\r\n",
    "\r\n",
    "\r\n",
    "    # For each fold's train index and validation index\r\n",
    "    for train_index, validation_index in t_v_indexes:\r\n",
    "\r\n",
    "        cur_train_fold_x = x_train.iloc[train_index]\r\n",
    "        cur_train_fold_y = y_train.iloc[train_index]\r\n",
    "\r\n",
    "        cur_validation_fold_x = x_train.iloc[validation_index]\r\n",
    "        cur_validation_fold_y = y_train.iloc[validation_index]\r\n",
    "\r\n",
    "        pipeline.fit(cur_train_fold_x, cur_train_fold_y)\r\n",
    "        sum += pipeline.score(cur_validation_fold_x, cur_validation_fold_y)\r\n",
    "    \r\n",
    "    # Add average to the performance\r\n",
    "    hyper_average[i] = sum/len(t_v_indexes)\r\n",
    "\r\n",
    "for key in hyper_average:\r\n",
    "    print(\"For degree {}, the average accuracy score is {}.\".format(key, round(hyper_average.get(key), 4)))\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_degree = max(hyper_average, key=hyper_average.get)\r\n",
    "print(\"The best prediction degree is {}, with average accuracy of {}\".format(best_degree, hyper_average.get(best_degree)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Similar to the pipeline, this whole process can be simplified using cross_val_score function from sklearn, it uses k-folds method cross validation by default\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "n = 20\r\n",
    "\r\n",
    "hyper_average = [None] * n\r\n",
    "\r\n",
    "for i in range(n):\r\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree=i+1), LinearRegression())\r\n",
    "    hyper_average[i] = np.mean(cross_val_score(pipeline, x_train, y_train, cv=5))\r\n",
    "\r\n",
    "# Plus one because list are 0-indexed, unlike how we defined our dictionary\r\n",
    "best_degree = hyper_average.index(max(hyper_average))\r\n",
    "print(\"The best prediction degree is {}, with average accuracy of {}\".format(best_degree+1, hyper_average[best_degree]))\r\n",
    "\r\n",
    "plt.figure(figsize=(15,6))\r\n",
    "plt.plot(np.arange(1, 21), hyper_average, color=\"purple\")\r\n",
    "plt.xlabel(\"Model Complexity (degree)\")\r\n",
    "plt.ylabel(\"Accuracy Score\")\r\n",
    "plt.title(\"Accuracy score from different degrees\")\r\n",
    "plt.xlim(1, 20)\r\n",
    "plt.ylim(0.990, 1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion: our best degree is 11"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training (Parameter optimization)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "\r\n",
    "model = make_pipeline(PolynomialFeatures(degree=best_degree+1), LinearRegression())\r\n",
    "model.fit(x_train, y_train)\r\n",
    "\r\n",
    "print(\"Model training completed\")\r\n",
    "rand = np.array([ [random.randint(10, 80)] ])\r\n",
    "print(\"Trying to predict a person with a weight of {} will have a height of {}\".format(rand[0][0], round(model.predict(rand)[0][0], 2)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How does it look like?\r\n",
    "\r\n",
    "x_test = x_test.sort_values(\"Weight\")\r\n",
    "y_test = y_test.reindex(x_test.index)\r\n",
    "\r\n",
    "plt.figure(figsize=(15, 6))\r\n",
    "plt.scatter(x, y, color=\"purple\")\r\n",
    "plt.plot(x_test, model.predict(x_test), color=\"black\", linewidth=5)\r\n",
    "plt.xlabel(\"Weight\")\r\n",
    "plt.ylabel(\"Height\")\r\n",
    "plt.title(\"Height VS Weight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score = model.score(x_test, y_test)\r\n",
    "print(\"Model Accuracy: {}\".format(round(accuracy_score,4)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This is almost 100% correct everytime, the best we can do avoiding overfitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}