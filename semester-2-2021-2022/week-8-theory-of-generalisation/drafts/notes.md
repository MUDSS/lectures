
The generalisation refers to predict unknown results (out sample) from known data (in sample)
- Return to the initial of ML, the generalisation of data to uncover process, the learning problem. We want learning, not memorising
- Unknown target function -> data -> learning models ->prediction
  - Learning models = learning algorithm + hypothesis set (can be anything or can be restricted, the structure is determined by learning models)
- In reality, maybe an impossible task, because the target function can be anything. Take as example of a sequence 1,2,3 and there are million ways to follow that sequence which each of them can be true and stated with a formula (hypothesis).

- Then, is learning feasible, does this all make sense?
- And the answer yes, assuming that we will never get the target function, we can get close to it with certain margin toleration.
  - Furthermore, we need to have a determine size of data inorder to conclude the result function relies inside margin
  - The form is by Hoeffding's inequality. It tells about the verification, not about learning
- To be learning, there must be multiple bins (hypothesis through the Hoeffding's indequality), and the upper bound gets loosen when the number of size of hypothesis set increases. Therefore the more complex is a model or hypothesis, the more reduced effect has Hoeffding. This is even maximized when adding M

- Target function is better defined as probability function, because of noise targets
- Based on in sample, we can calculate in sample error, and our goal is to reduce it. Affects to both the learning algorithm and hypothesis
- Learning is feasible in probabilistic sense. And this means that E_out is probably approximate to E_in.
- Therefore, when we say a model had a good hypothesis and made a good learning process when E_out is close to 0. To achieve this, we have two parts:
  - E_out is close to E_in, this is bounded and guranteed by Hoeffdings inequality. If not bounded, you can train your best model in in sample, but have a terrible performance out sample. This reminds the train and test, only that in a more global sense, all our data is train and when the model is really under test is the out sample
  - The second one is by tending close E_in to 0, this is simply working with in sample data and try to minimize our errors. E.g. Least squares in linear regression
- By completing the above two, will would have accomplished proving generalisation is possible, and our model can do well out sample too
- So, we are now left with the problem of bounding Hoeffding inequality with M (which can be infinitive), and try to train our model to lower as much as we can E_in

- The E_in is easily obtained by calculating the errors of each point in sample and average it. e.g. square error in linear regression (h(x)-f(x))^2, or binary error
- Distinguish between optimizer (what corrects the hypothesis to a better one), and error function, which is related, but is used to evaluate the error of current hypothesis

- M is almost useless in all cases, as simple as perceptron, the M can be infinitive. But, we can improve M as bad events between different hypothesis are extremely overlapping
- We replace the M which is number of hypothesis in the total input space that differs in at least one of the input space points, to m, which is the number of hypothesis that differs in at least one of the sample points
  - This hugely decreases M as all infinitive movements in input space is reduced to number of movements that makes different sample point prediction
- Hypothesis set for M: hypothesis   -specified-> Hypothesis set for m: Dichotomy
- Growth function: count the number of dichotomies to substitute M, therefore we consider the worst case, 2^N
  - It depends on N and is obtained under certain hypothesis set, so itÂ´s mH(N) and mH(N)<=2^N
  - Growth function example:
    - Sky and ground (N+1)
    - Painting wall (1/2\*N^2 + 1/2*N + 1)
- Why look at growth function, because if we substitute, and obtain the the Hoeffding inequality, AND obtain growth function as polynomical, we can eventually keep the right hand side lower than 1 (Not dependent on N, because exponential function grows faster than the polynomical)
- This will prove learning is possible. If you are given enough data, you can generalise from finite sample, to a infinite general out sample space.
- Breakpoints is the number of N in which, till not arriving this number we can generate all possibilities, but when we arrive not all possible dichotomies can be created.We say that K is a break point for H (a particular hypothesis set and model)
- Break point points the fact it exists limits the growth function not to be 2^N always
  - For perceptron:
    - 3 -> all possibilities 8
    - 4 -> not all possibilities 14 and not 16 -> means that perceptron is limited,and growth function is not that bad
    - If when N = 4 we dont get all possibilities in perceptron, break point for perceptron is K = 4
  - For sky and ground model
    - When N = 2, we dont get all N^2 = 4, so K = 2 for whole model
  - For Painting wall model
    - When N = 3, break point, we dont get all N^2
- Lets summarize how K determines the growth function
  - If no K, then growth function = 2^N
  - If yes a K, there is a growth function lower, and it is going to be polynomial (to be proved)
    - Why is that, because a break point means a huge constraint and hence reduction of m in any N bigger than K. E.g. with perceptron, the m used to be 1024 for N = 10, but with K = 3 as constraint, it's going to be very small
- Therefore limits the upperbound of hypothesis set.
- So, if you can tell

- We need to proof growth function is polynomial and proof M can be replaced by the growth function
- Proof mH(N) is polynomial
  - Say that B(N, K) is the number of maximum dichotomies given number N and break points K. This means that this B is deterministic regardless of the model, hypothesis, etc., only relies on N and K
  - Consider all possible dichotomies exposed in a table x1 to xn, where any possible combinations respecting the breaking point are allowed
  - Then separate these rows into alpha (rows with single extention in xn) and 2 betas (beta+ and beta- where are pairs of rows that have variation in last xn)
  - Hence B(N, K) is alpha + 2*beta, you cant find any row that does not satisfy any of these conditions
    - Alpha + beta <= B(N-1, k) because if a row is ok with x1 to xn, must be ok with x1 to xn-1. The reason why <= is because we are not sure this is the best way to maximize the maximum number of dichotomies (hypothesis), therefore we are not calculating upperbound of B(N-1, k)
    - Beta without xn is at most B(N-1, K-1). Because we know that till xn, adding a +1 and -1 is totally possible for beta groups. Lets say that beta has k-1 points, and has all possible patterns, but if this group have +1 -1, means that it can have up to all posibilities on k, which is against K is breaking point in B, therefore the only explanation is that in that k-1 points, it is not possible to have all patterns, hence beta's breaking point is atleast k-1. Therfore B(N-1, K-1)
  - alpha + 2*beta <= B(N-1, k) + B(N-1, k-1)
  - So, till now, we are able to compute B(N, K) by recursion. But we want to have an analitical solution for B(N, K), that is only by giving N and K, you can compute directly what is the upperbound B.
  - We proof B(N, K) <= sum(C(N, i), 0, k-1)by induction
    - Step 1. Boundary condition
    - Step 2. Assume it is true for B(N-1, k) and B(N-1, k-1)
    - Step 3. Prove it is true for B(N, K) by sum(C(N, i), 0, k-1) = sum(C(N-1, i), 0, k-1) + sum(C(N-1, i), 0, k-2)
      - Some prove
  - And yes! It is a polynomial, we just proved that B(N, K) is smaller or equal to the sum(C(N, i), 0, k-1), and this is polynomial!
- We can test with examples and find the growth function upper bound
  - Sky and ground (K = 2): N+1
  - Painting the wall (K = 3): (1/2\*N^2 + 1/2*N + 1)
  - Perceptron (K=4): (1/6*N^3 + 5/6*N + 1) This means that no matter how the N increases in perceptron, the number of hypothesis, dichotomies, or lines we can draw to separate points WILL NEVER EXCEED this polynomical statement
- We now want to prove M can be substituted by mH(N)
  - By one side, we can think M is acting very bad because it's restricted by union bound when we consider the worst case, eventually, this will cover the entire out sample space with bad events. And thats the reason why we say M can tend to infinitive and therefore Hoeffding loses its constraining power.
  - To solve this, we consider another proved bound, VC bound, which limits the bad event area into a smaller place, limiting how bad the M can be. Not going into deep prove, but essentially it relates to mH(N) because the bad events are now only relevant if it makes any change in in sample errors
  - Another problem is how do we make sure mH(N) relates to E_out, remembering that mH(N) is purely coming from E_in. The solution is to consider a second example that comes from E_out each time E_in is retrieved, then we can compare the trackability between E_out with E_in and second E_in with first E_in.
  - Finally, this results The Vapnik-Chervonenkis Inequality, one of the most important theoritical result in machine learning

- VC dimension of a hypothesis set H is denoted by dvc(H) by which the largest number N for which growth function is 2^N. So, if VC dimension is dvc, break point is dvc +1.
  - N <= dvc, then these points can be shattered
  - N > dvc, then N is K, which is a break point for H
- We substitute sum(C(N, i), 0, k-1) to sum(C(N, i), 0, d), and d will be the highest degree of the polynomial
- if d is finite -> g belong H will generalise
- As far, we have proved how dvc can constraint the upper bound in this dichotomy 2D model. How about 3D model?
- In general, dvc = d + 1 by proving dvc<= d+1 and dvc>= d+1
- dvc mathematical meaning is the degrees of freedom, the effectvie number of prameters
- In a practical conclusion, not mathematical statement
  - Proportionality in dvc and the number of sample needed to have same performance
  - Rule of thumb, when 10*N>= dvc, the performance is usually good 

- Bias is the difference between the average final hypothesis and target function (corresponds to the accuracy)
- Variance is the variability of any hypothesis formated compared to the target function (corresponds to the precision)
- Need to trade bias and variance to make lower in total
- Bias and variance tradeoff, the model complexity must match to the data resources, not to the target complexity